
# pacman imports
from pacman.interfaces.abstract_provides_provenance_data import \
    AbstractProvidesProvenanceData
from pacman.model.partitioned_graph.partitioned_vertex import PartitionedVertex

# spinn front end common imports
from spinn_front_end_common.interface.buffer_management.buffer_models.\
    abstract_receive_buffers_to_host import \
    AbstractReceiveBuffersToHost
from spinn_front_end_common.utilities import helpful_functions

# data spec imports
from data_specification import utility_calls as data_specification_utilities

# spynnaker imports
from spynnaker.pyNN.utilities import constants

# general imports
import struct


class PopulationPartitionedVertex(
        PartitionedVertex, AbstractReceiveBuffersToHost,
        AbstractProvidesProvenanceData):
    """ Represents a sub-set of atoms from a AbstractConstrainedVertex
    """

    def __init__(
            self, buffering_output, resources_required, label,
            constraints=None):
        """
        :param buffering_output: True if the vertex is set to buffer output,\
                    False otherwise
        :param resources_required: The approximate resources needed for\
                    the vertex
        :type resources_required:\
                    :py:class:`pacman.models.resources.resource_container.ResourceContainer`
        :param label: The name of the subvertex
        :type label: str
        :param constraints: The constraints of the subvertex
        :type constraints: iterable of\
                    :py:class:`pacman.model.constraints.abstract_constraint\
                    .AbstractConstraint`
        :raise pacman.exceptions.PacmanInvalidParameterException:
                    * If one of the constraints is not valid
        """
        AbstractReceiveBuffersToHost.__init__(self)
        PartitionedVertex.__init__(
            self, resources_required=resources_required, label=label,
            constraints=constraints)
        AbstractProvidesProvenanceData.__init__(self)

        self._buffering_output = buffering_output

    def buffering_output(self):
        return self._buffering_output

    def is_receives_buffers_to_host(self):
        return True

    def write_provenance_data_in_xml(
            self, file_path, transceiver, message_store, placement=None):
        """ Write the provenance data using XML
        :param file_path: the file path to write the provenance data to
        :param transceiver: the SpinnMan interface object
        :param message_store: the messages generated by the provenance data \
        for a core.
        :param placement: the placement object for this subvertex or None if\
                    the system does not require a placement object
        :return: None
        """
        # TODO this needs to be moved, once sergio's and rowley's branches are merged.
        # Get the App Data base address for the core
        # (location where this cores memory starts in sdram and region table)
        app_data_base_address = transceiver.get_cpu_information_from_core(
            placement.x, placement.y, placement.p).user[0]
        provenance_data_region_base_address = \
            data_specification_utilities.get_region_base_address_offset(
                app_data_base_address,
                constants.POPULATION_BASED_REGIONS.PROVENANCE_DATA.value)
        provenance_data_region_base_address_offset = \
            helpful_functions.read_data(
                placement.x, placement.y, provenance_data_region_base_address,
                4, "<I", transceiver)

        # deduce the base address location for the provenance data region in
        # sdram
        provenance_data_base_address =\
            provenance_data_region_base_address_offset + app_data_base_address

        # todo this was a function call, but alas the call only returned the first
        # get data from the machine
        data = buffer(transceiver.read_memory(
            placement.x, placement.y, provenance_data_base_address,
            constants.PROVENANCE_DATA_REGION_SIZE_IN_BYTES))
        provenance_data = struct.unpack_from("<IIIIII", data)

        saturation_count = provenance_data[
            constants.PROVENANCE_DATA_ENTRIES.SATURATION_COUNT.value]
        input_buffer_overflows = provenance_data[
            constants.PROVENANCE_DATA_ENTRIES.BUFFER_OVERFLOW_COUNT.value]
        the_number_of_pre_synaptic_events = provenance_data[
            constants.PROVENANCE_DATA_ENTRIES.PRE_SYNAPTIC_EVENT_COUNT.value]
        transmission_event_overflow = provenance_data[
            constants.PROVENANCE_DATA_ENTRIES.TRANSMISSION_EVENT_OVERFLOW.value]
        timer_tic_queue_overloaded = provenance_data[
            constants.PROVENANCE_DATA_ENTRIES.TIMER_TIC_QUEUE_OVERLOADED.value]
        dma_queue_overloaded = provenance_data[
            constants.PROVENANCE_DATA_ENTRIES.DMA_QUEUE_OVERLOADED.value]

        self._add_core_warnings_if_applicable(
            saturation_count, input_buffer_overflows,
            transmission_event_overflow, timer_tic_queue_overloaded,
            dma_queue_overloaded, message_store, placement)

        self._generate_xml(
            file_path, saturation_count, input_buffer_overflows,
            the_number_of_pre_synaptic_events, transmission_event_overflow,
            timer_tic_queue_overloaded, dma_queue_overloaded, placement)

    @staticmethod
    def _add_core_warnings_if_applicable(
            saturation_count, input_buffer_overflows,
            transmission_event_overflow, timer_tic_queue_overloaded,
            dma_queue_overloaded, message_store, placement):

        # check for errors
        if saturation_count != 0:
            message_store.add_core_message(
                placement.x, placement.y, placement.p,
                "The weights from the synapses saturated on {} occasions. "
                "If this is not expected, you can increase the "
                "\"spikes_per_second\" and / or \"ring_buffer_sigma\" "
                "values located within the .spynnaker.cfg file."
                .format(saturation_count), "")
        if input_buffer_overflows != 0:
            message_store.add_core_message(
                placement.x, placement.y, placement.p,
                "The input buffer lost packets on {} occasions. This is "
                "often a sign that the system is running too quickly for the"
                " number of neurons per core, please increase the timer_tic "
                "or time_scale_factor or decrease the number of neurons "
                "per core.".format(input_buffer_overflows), "")
        if transmission_event_overflow != 0:
            message_store.add_core_message(
                placement.x, placement.y, placement.p,
                "The input buffer lost packets on {} occasions. This is "
                "often a sign that the system is running too quickly for the"
                " number of neurons per core, please increase the timer_tic "
                "or time_scale_factor or decrease the number of neurons "
                "per core.".format(transmission_event_overflow), "")
        if timer_tic_queue_overloaded != 0:
            message_store.add_core_message(
                placement.x, placement.y, placement.p,
                "The timer tic queue overloaded on {} occasions. This is "
                "often a sign that the system is running too quickly for the"
                " number of neurons per core, please increase the timer_tic "
                "or time_scale_factor or decrease the number of neurons "
                "per core.".format(timer_tic_queue_overloaded), "")
        if dma_queue_overloaded != 0:
            message_store.add_core_message(
                placement.x, placement.y, placement.p,
                "The DMA queue overloaded on {} occasions. This is "
                "often a sign that the system is running too quickly for the"
                " number of neurons per core, please increase the timer_tic "
                "or time_scale_factor or decrease the number of neurons "
                "per core.".format(timer_tic_queue_overloaded), "")

    @staticmethod
    def _generate_xml(
            file_path, saturation_count, input_buffer_overflows,
            the_number_of_pre_synaptic_events, transmission_event_overflow,
            timer_tic_queue_overloaded, dma_queue_overloaded, placement):

        # store data in xml
        from lxml import etree

        # generate tree elements
        root = etree.Element(
            "located_at_{}_{}_{}".format(placement.x, placement.y, placement.p))
        saturation_count_element = \
            etree.SubElement(root, "Times_synaptic_weights_have_saturated")
        input_buffer_overflows_element = \
            etree.SubElement(root, "Times_the_input_buffer_lost_packets")
        the_number_of_pre_synaptic_events_element = \
            etree.SubElement(root, "Total_pre_synaptic_events")
        transmission_event_overflow_element = \
            etree.SubElement(root, "Times_the_transmission_of_spikes_overran")
        timer_tic_queue_overloaded_element = \
            etree.SubElement(root, "Times_the_timer_tic_queue_was_overloaded")
        dma_queue_overloaded_element = \
            etree.SubElement(root, "Times_the_dma_queue_was_overloaded")

        # add values
        saturation_count_element.text = str(saturation_count)
        input_buffer_overflows_element.text = str(input_buffer_overflows)
        the_number_of_pre_synaptic_events_element.text = \
            str(the_number_of_pre_synaptic_events)
        transmission_event_overflow_element.text = \
            str(transmission_event_overflow)
        timer_tic_queue_overloaded_element.text = \
            str(timer_tic_queue_overloaded)
        dma_queue_overloaded_element.text = str(dma_queue_overloaded)

        # write xml form into file provided
        writer = open(file_path, "w")
        writer.write(etree.tostring(root, pretty_print=True))
        writer.flush()
        writer.close()
